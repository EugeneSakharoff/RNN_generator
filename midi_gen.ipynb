{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "midi_gen.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "source": [
        "!pip install mido\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import mido"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s1aEQMD9u6W"
      },
      "source": [
        "resolution = 24\n",
        "\n",
        "notes = 'abcdefghijkl'\n",
        "octaves = 'ABCDEFGHI'\n",
        "shifts='abcdefghijkl'\n",
        "\n",
        "min_note = 12\n",
        "max_note = 96\n",
        "notes_range = range(min_note,max_note)\n",
        "\n",
        "def tick_based_encoding(song):\n",
        "  data = []\n",
        "  abs_time = 0\n",
        "  for msg in song.tracks[2]:\n",
        "    abs_time += msg.time//resolution\n",
        "    while len(data)<abs_time+1:\n",
        "      data.append([0.0 for i in notes_range])\n",
        "    if msg.type == 'note_on':\n",
        "      data[abs_time][msg.note] = 1.0\n",
        "  return data\n",
        "\n",
        "def sequentional(song):\n",
        "    data = []\n",
        "    for msg in song.tracks[2]:\n",
        "        current_octave = 4\n",
        "        if msg.type == 'note_off':\n",
        "          if msg.time>0:\n",
        "            data.append(msg.time)\n",
        "        if msg.type == 'note_on':\n",
        "            data.append(msg.time)\n",
        "            data.append(octaves[msg.note//12])\n",
        "            data.append(notes[msg.note%12])\n",
        "    return data\n",
        "\n",
        "def encode_shifts(song):\n",
        "    data = []\n",
        "    time = 0\n",
        "    prev = 60\n",
        "    for msg in song.tracks[2]:\n",
        "        time+=msg.time\n",
        "        if msg.type == 'note_on':\n",
        "            data.append(time)\n",
        "            time = 0\n",
        "            shift = msg.note-prev\n",
        "            prev = msg.note\n",
        "            while shift>11:\n",
        "              data.append('>')\n",
        "              shift -= 12\n",
        "            while shift<-11:\n",
        "              data.append('<')\n",
        "              shift += 12\n",
        "            if shift<0:\n",
        "              data.append('-')\n",
        "              shift = abs(shift)\n",
        "            shift = shifts[shift]\n",
        "            data.append(shift)\n",
        "    return data\n",
        "\n",
        "\n",
        "song = mido.MidiFile('/content/MoonlightExtended.mid')\n",
        "\n",
        "data =tick_based_encoding(song)\n",
        "data[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7I1j7r3I-XE"
      },
      "source": [
        "vocab = list(set(data))\n",
        "len(vocab),len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UHJDA39zf-O"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "seq_length_fast = 10\n",
        "seq_length_slow = 150\n",
        "\n",
        "\n",
        "\n",
        "def split_input_target_seq(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[-1]\n",
        "    return input_text, target_text\n",
        "\n",
        "\n",
        "\n",
        "#char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "#idx2char = vocab\n",
        "data*=100\n",
        "#text_as_int = np.array([char2idx[c] for c in data])\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "\n",
        "sequences_slow = char_dataset.batch(seq_length_slow+1, drop_remainder=True)\n",
        "#sequences_fast= char_dataset.batch(seq_length_fast+1, drop_remainder=True)\n",
        "\n",
        "sequences_slow= sequences_slow.map(split_input_target)\n",
        "#sequences_fast= sequences_fast.map(split_input_target)\n",
        "\n",
        "dataset_slow = sequences_slow.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "#dataset_fast = sequences_fast.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t2KGdAYu4A1"
      },
      "source": [
        "dataset_slow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "#vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "#embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 512\n",
        "\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.categorical_crossentropy(labels, logits, from_logits=False)\n",
        "\n",
        "def build_model(rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    #tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "    #                          batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        #return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),       \n",
        "    tf.keras.layers.Dense(len(notes_range))\n",
        "  ])\n",
        "  return model#, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwsrpOik5zhv"
      },
      "source": [
        "model = build_model(\n",
        "  #vocab_size = len(vocab),\n",
        "  #embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "#modelfast.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "source": [
        "EPOCHS=20\n",
        "model.fit(dataset_slow, epochs=EPOCHS)\n",
        "model.save_weights('weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvbsz6pYFBs8"
      },
      "source": [
        "tf.expand_dims(data[:10],0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk2WJ2-XjkGz"
      },
      "source": [
        "modelslow,modelfast = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "modelslow.load_weights('slowweights')\n",
        "modelfast.load_weights('fastweights')\n",
        "modelslow.build(tf.TensorShape([1, None]))\n",
        "modelfast.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvuwZBX5Ogfd"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  num_generate = 1000\n",
        "\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        " \n",
        "  modelslow.reset_states()\n",
        "  modelfast.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      if i%128==0:\n",
        "        temperature = np.random.random()/2+0.4\n",
        "      predictions_slow = modelslow(input_eval)\n",
        "      #predictions_fast = modelfast(input_eval)     \n",
        "      predictions_slow = tf.squeeze(predictions_slow, 0)/ temperature\n",
        "      #predictions_fast = tf.squeeze(predictions_fast, 0) / temperature \n",
        "\n",
        "      predicted_id_slow = tf.random.categorical(predictions_slow, num_samples=1)[-1,0].numpy()\n",
        "      #predicted_id_fast = tf.random.categorical(predictions_fast, num_samples=1)[-1,0].numpy()\n",
        "      input_eval = tf.expand_dims([predicted_id_slow], 0)\n",
        "      text_generated.append(idx2char[predicted_id_slow])\n",
        "      #if i%3==0:\n",
        "       # text_generated.append(idx2char[predicted_id_slow])\n",
        "      #else:\n",
        "      #  text_generated.append(idx2char[predicted_id_fast])\n",
        "\n",
        "\n",
        "      \n",
        " \n",
        "\n",
        "  return (start_string+text_generated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktovv0RFhrkn"
      },
      "source": [
        "gen=generate_text(model, start_string=[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-pxCYpqB0zu"
      },
      "source": [
        "\n",
        "def from_seq():\n",
        "  song = mido.MidiFile()\n",
        "  track = mido.MidiTrack()\n",
        "  song.ticks_per_beat=96\n",
        "  time=0\n",
        "  octave=4\n",
        "  for i,msg in enumerate(gen):\n",
        "      if isinstance(msg,int):\n",
        "        time += msg\n",
        "      elif msg in octaves:\n",
        "        octave = octaves.index(msg)\n",
        "      elif msg in notes:\n",
        "        note = notes.index(msg)\n",
        "        track.append(mido.Message('note_on', note = octave*12+note, time = time))\n",
        "        track.append(mido.Message('note_off', note = octave*12+note, time = 0))\n",
        "        time = 0\n",
        "\n",
        "  song.tracks.append(track)\n",
        "  song.save('/content/output.mid')\n",
        "\n",
        "def from_shifts():\n",
        "  song = mido.MidiFile()\n",
        "  track = mido.MidiTrack()\n",
        "  song.ticks_per_beat=96\n",
        "  time=0\n",
        "  prev=60\n",
        "  minusflag = False\n",
        "  for i,msg in enumerate(gen):\n",
        "      if isinstance(msg,int):\n",
        "          time += msg\n",
        "      elif msg == '>':\n",
        "          prev+=12\n",
        "      elif msg == '<':\n",
        "          prev-=12\n",
        "      elif msg =='-':\n",
        "          minusflag=True\n",
        "      elif msg in shifts:\n",
        "          if minusflag:\n",
        "              note = prev-shifts.index(msg)\n",
        "          else:\n",
        "              note = prev+shifts.index(msg)\n",
        "          minusflag = False\n",
        "          note = min(120,max(note,0))\n",
        "          prev = note\n",
        "          track.append(mido.Message('note_on', note = note, time = time))\n",
        "          track.append(mido.Message('note_off', note = note, time = 0))\n",
        "          time = 0\n",
        "\n",
        "  song.tracks.append(track)\n",
        "  song.save('/content/output.mid')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z87HvuMnLrsd"
      },
      "source": [
        "from_shifts()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}